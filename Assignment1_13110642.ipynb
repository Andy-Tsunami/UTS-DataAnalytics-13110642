{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1-13110642.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andy-Tsunami/UTS-DataAnalytics-13110642/blob/master/Assignment1_13110642.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3hC90qPfNaI",
        "colab_type": "text"
      },
      "source": [
        "#Review Report on Generative Adversarial Nets\n",
        "###Advanced Data Analytics\n",
        "###Andy Tsui - 13110642\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wEMkkzxhvXz",
        "colab_type": "text"
      },
      "source": [
        "##Introduction\n",
        "This report will review the paper \"Generative Adversarial Nets\" authored by Goodfellow and his peers (2014). [A link to the github version can be found here.](https://github.com/Andy-Tsunami/UTS-DataAnalytics-13110642/blob/master/Assignment1_13110642.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo8OSd2XiA2I",
        "colab_type": "text"
      },
      "source": [
        "##Content\n",
        "The paper \"Generative Adversarial Nets\" (Goodfellow et al. 2014) proposed a new concept where a sample is taken to train two models together which then compete against each other. The model is now widely known as GAN, short for Generative Adversarial Nets. The first model known as discriminative model D does everything it can to increase the chance of the second model; generative model G of making a mistake and vice versa. By doing so both models continuously improve upon these mistakes until they make a near identical match to the origin of where the sample came from. In comparison to many other classifiers or methods, GAN does not utilise the Markov Chains; which means it does not need to use a decision tree like framework because the discriminative model and generative model compete with one another as adversaries. To ensure GAN can accurately predict a distribution, G and D models must be in sync with each other throughout the training process, hence is compared to a game where players take turns.  \n",
        "To prove the framework was successful, the authors pass random noise through a multilayer perceptron; i.e. an algorithm for both the generative model and discriminative model. \n",
        "One dataset they tested the framework on was the Toronto Face Database (Goodfellow et al. 2014) in which the generator was able to generate samples as shown in the figure below.\n",
        "<br><br>\n",
        "\n",
        "<img align=\"center\" src=\"https://github.com/Andy-Tsunami/UTS-DataAnalytics-13110642/blob/master/tfd.jpg?raw=true\" width=\"400\"/>\n",
        "\n",
        "  \n",
        "Figure 1 - The GAN framework is able to generate images like those in the database with high accuracy and detail.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG4KNDM_iFX2",
        "colab_type": "text"
      },
      "source": [
        "##Innovation\n",
        "As GAN was only developed in 2014 (Goodfellow et al. 2014), it is still a relatively new generative model and new ways of using it are still being researched. The research done by Ian Goodfellow and fellow peers laid the base work for GAN to be used for various image transformations (2014). Presently, GAN is mostly commonly known for its use in graphic generation by well-known company NVIDIA (Peng 2018). Graphic Processing Units (GPU) created by NVIDIA can use GAN to produce AI-generated images that look realistic. This includes images such as human faces, landscapes and animals (Peng 2018). The sample that the image is generated from also does not have to be in great detail. The samples can be as simple as a selection of random numbers or inputs in a certain pattern, GAN will then generate a model with much more detail. An example of this is demonstrated on the [GAN Lab](https://poloclub.github.io/ganlab/) (Kahng et al. 2019).\n",
        "\n",
        "The algorithm used in GAN which is based on the adversarial relationship between generator G and discriminator D is shown below (Goodfellow et al. 2014):\n",
        "<br><br>\n",
        "$$\\min\\limits_{G}\\max\\limits_{D}V(D,G)=E_{x\\sim p_{data}(x)}[logD(x)]+E_{z\\sim p_{z}(z)}[log(1-D(G(z)))]$$\n",
        "<br><br>\n",
        "GAN is being used in areas of gaming, animation character generation, e-commerce, music generation, anomaly detection in medical fields and enhancing resolution of images (Hui 2018). In e-commerce GAN can be used for example, by using one photo of a person posing in certain clothing and then creating new images with different poses or clothing. This reduces the time required for models and photographers when trying to advertise clothing online to sell making it more cost effective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIRD-ptdiHZX",
        "colab_type": "text"
      },
      "source": [
        "##Technial Quality\n",
        "\n",
        "Overall the paper was able to explain how GAN works and the future potentials of the framework. For the experiment section, steps are provided to show what parameters were involved such as which generator nets & discriminator nets were used and fitting a Gaussian Parzen window (Goodfellow et al. 2014). It also provides where the model met challenges which would help future research and potentially find ways to overcome these challenges. The paper however lacked depth and a good explanation of the concept which may be due to a complete understanding of the capabilities of the framework at the time. Further research into this framework such as the paper done by Hong and his peers (2019) explains the concept in much greater depth.\n",
        "\n",
        "The paper noted that the GAN framework is not necessarily better than others, but compares to others mainly because of its absence of the use of Markov chains (Goodfellow et al. 2014). This shows a sizeable difference in how a GAN model works compared to other generative models making it stand out. A section discussing ‘Related Works’ (Goodfellow et al. 2014) was also included in the paper to further strength its proposal and how it differs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBa1k9NyiJon",
        "colab_type": "text"
      },
      "source": [
        "##Application and X-Factor\n",
        "As further research has shown, the research of the paper has proven to become very successful. NVIDIA is one of the leading companies in GPUs and has invested heavily in GAN technology. It has used this technology to allow its GPUs to generate realistic virtual graphics for games and other virtual reality purposes. Virtual reality is where GAN technology would really shine in the future as it could be used to provide training to robots in life-like simulations, allow astronauts to see a planets surface and potential hazards before even stepping foot on it, or perhaps even allow someone who is blind to see a virtual world which is identical to the real world.\n",
        "\n",
        "I think the GAN framework has a lot more potential and will be used in many other applications in the future.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCM_4cP6iMmM",
        "colab_type": "text"
      },
      "source": [
        "##Presentation\n",
        "\n",
        "The presentation of the paper was well formatted and flowed well. The 'Theoretical Results' section was difficult to understand but necessary to allow verification of the method and future research. Figures and formulas were well explained, and references included. The conclusion provided statements where improvements in the framework could be made; thus, a platform for future research to be done. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR2Lm5qQiPDc",
        "colab_type": "text"
      },
      "source": [
        "##References\n",
        "\n",
        "1. Goodfellow, I.J., Puget-A badle, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Benglo, Y. & 2014, Generative Adversarial Nets, University of Montreal, Montreal, QC H3C 3J7.\n",
        "\n",
        "2. Hong, Y., Hwang, U., Yoo, J. & Yoon, S. 2019, 'How Generative Adversarial Networks and Their Variants Work: An Overview', ACM Computing Surveys (CSUR), vol. 52, no. 1, p. 10.\n",
        "\n",
        "3. Hui, J. 2018, GAN — Some cool applications of GANs., viewed 27th August 2019, \n",
        "[https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900](https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900)\n",
        "\n",
        "4. Kahng, M., Thorat, N., Chau, P., Viegas, F. & Wattenberg, M. 2019, GAN Lab, viewed 26th August 2019, [https://poloclub.github.io/ganlab/](https://poloclub.github.io/ganlab/)\n",
        "\n",
        "5. Peng, T. 2018, GAN 2.0: NVIDIA’s Hyperrealistic Face Generator, viewed 27th August 2019, [https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf](https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf)\n",
        "\n"
      ]
    }
  ]
}